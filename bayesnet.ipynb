{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am getting the code from: https://github.com/navreeetkaur/bayesian-network-learning\n",
    "# Specifically baysnet.py,\n",
    "# So, this notebook needs to be called from other notebooks,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "#Wow, after 5 years, it's still from futures!! Damn\n",
    "\n",
    "from collections import OrderedDict\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph_Node():\n",
    "\t\"\"\"Our graph consists of a list of nodes where \n",
    "    each node is represented as follows\"\"\"\n",
    "\n",
    "\tdef __init__(self, name, n, vals):\n",
    "\t\tself.Node_Name = name # Variable name \n",
    "\t\tself.nvalues = n # Number of categories a \n",
    "        #variable represented by this node can take\n",
    "        \n",
    "\t\tself.values = vals # Categories of possible values\n",
    "\t\tself.Children =  [] # Children of a particular node \n",
    "        #- these are index of nodes in graph.\n",
    "        \n",
    "\t\tself.Parents = [] # Parents of a particular node\n",
    "        #- note these are names of parents\n",
    "        \n",
    "\t\tself.CPT = []\n",
    "\t\tself.cpt_data =  pd.DataFrame() # conditional \n",
    "        # probability table as a DataFrame (counts) \n",
    "        \n",
    "\t\tself.markov_blanket = [] # List of nodes in \n",
    "        # the Markov Blanket - note that these are the\n",
    "        # names of the nodes\n",
    "\n",
    "\tdef get_name(self):\n",
    "\t\treturn self.Node_Name\n",
    "\n",
    "\tdef get_children(self):\n",
    "\t\treturn self.Children\n",
    "\n",
    "\tdef get_Parents(self):\n",
    "\t\treturn self.Parents\n",
    "\n",
    "\tdef get_n_parents(self):\n",
    "\t\treturn len(self.Parents)\n",
    "\n",
    "\tdef get_CPT(self):\n",
    "\t\treturn self.CPT\n",
    "\n",
    "\tdef get_nvalues(self):\n",
    "\t\treturn self.nvalues\n",
    "\n",
    "\tdef get_values(self):\n",
    "\t\treturn self.values\n",
    "\n",
    "\tdef set_CPT(self, new_CPT):\n",
    "\t\tdel(self.CPT[:])\n",
    "\t\tself.CPT = new_CPT\n",
    "\n",
    "\tdef set_counts(self, new_counts):\n",
    "\t\tdel(self.counts[:])\n",
    "\t\tself.counts = new_counts\n",
    "\n",
    "\tdef set_MB(self, new_mb):\n",
    "\t\tself.markov_blanket = new_mb\n",
    "\n",
    "\tdef set_cpt_data(self, new_cpt_data):\n",
    "\t\tself.cpt_data.drop(columns = list(self.cpt_data.columns))\n",
    "\t\tself.cpt_data = new_cpt_data\n",
    "\n",
    "\tdef set_Parents(self, Parent_Nodes):\n",
    "\t\tself.Parents = Parent_Nodes\n",
    "\n",
    "\tdef add_child(self, new_child_index):\n",
    "\t\tif new_child_index in self.Children:\n",
    "\t\t\treturn 0\n",
    "\t\telse:\n",
    "\t\t\tself.Children.append(new_child_index)\n",
    "\t\t\treturn 1\n",
    "\n",
    "\tdef print_node(self):\n",
    "\t\tprint(self.Node_Name)\n",
    "\t\tprint(self.values)\n",
    "\t\tprint(self.Parents)\n",
    "\t\tprint(self.CPT)\n",
    "\t\tprint\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class network():\n",
    "    \"\"\"\n",
    "    The whole network represted as a dictionary of nodes\n",
    "    Pres_Graph: \n",
    "        Ordered Dictionary - Keys: variable names, \n",
    "                            Values: Node Objects\n",
    "    MB:\n",
    "        Ordered Dictionary - Keys: variable names, \n",
    "                        Values: List of names of the nodes in the \n",
    "                        markob blanket of the key\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, Pres_Graph = OrderedDict(), \n",
    "                 MB = OrderedDict()):\n",
    "        self.Pres_Graph = Pres_Graph\n",
    "        self.MB = MB\n",
    "\n",
    "    def addNode(self, node):\n",
    "        self.Pres_Graph[node.Node_Name] = node\n",
    "\n",
    "    def netSize(self):\n",
    "        return len(self.Pres_Graph)\n",
    "        \n",
    "    def get_index(self, val_name):\n",
    "        try:\n",
    "            return self.Pres_Graph[val_name]\n",
    "        except:\n",
    "            print(\"No node of the name: \" + str(val_name))\n",
    "            print(\"Pres_Graph: \", self.Pres_Graph.keys())\n",
    "            return None\n",
    "\n",
    "    def get_nth_node(self, n):\n",
    "        return self.Pres_Graph.values()[n]\n",
    "\n",
    "    def search_node(self, val_name):\n",
    "        try:\n",
    "            return self.Pres_Graph[val_name]\n",
    "        except:\n",
    "            print(\"Node NOT found\")\n",
    "            return None\n",
    "\n",
    "    def get_parent_nodes(self, node):\n",
    "        parent_nodes = []\n",
    "        parents = node.get_Parents()\n",
    "        for p in parents:\n",
    "            parent_nodes.append(self.search_node(p))\n",
    "        return parent_nodes\n",
    "\n",
    "    def get_children(self, val_name):\n",
    "        Children = self.Pres_Graph[val_name].Children\n",
    "        c = []\n",
    "        for n in Children:\n",
    "            c.append(self.Pres_Graph.keys()[n])\n",
    "        return c\n",
    "\n",
    "    def set_mb(self):\n",
    "        for vals in self.Pres_Graph.keys():\n",
    "            self.MB[vals] = markov_blanket(self, vals)\n",
    "            \n",
    "\n",
    "    def normalise_cpt(self, X):\n",
    "        l = [X] + self.Pres_Graph[X].Parents + ['counts', 'p']\n",
    "        cpt = self.Pres_Graph[X].cpt_data\n",
    "        nvals = self.Pres_Graph[X].nvalues\n",
    "        cardinality = cpt.shape[0]\n",
    "        no_grps = int(cardinality/nvals)\n",
    "        list_dfs = []\n",
    "        df = pd.DataFrame()\n",
    "        i=0 \n",
    "        for n in range(no_grps):\n",
    "            curr_df = pd.DataFrame(cpt.iloc[i:i+nvals, :])\n",
    "            curr_df['p'] = normalise_counts(curr_df['counts'])\n",
    "            df = df.append(curr_df)\n",
    "            i = i + nvals\n",
    "        self.Pres_Graph[X].cpt_data = df[l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Reading network from .bif format \"\"\"\n",
    "def read_network(bif_filepath):\n",
    "    Alarm = network()\n",
    "    find = 0\n",
    "\n",
    "    with open(bif_filepath, 'r') as  myfile: \n",
    "        while True:\n",
    "            line = myfile.readline()\n",
    "            line = line.strip()\n",
    "\n",
    "            if line == '':\n",
    "                break\n",
    "\n",
    "            tokens = line.split()\n",
    "            first_word = tokens[0]\n",
    "\n",
    "\n",
    "            if first_word == \"variable\":\n",
    "                values = []\n",
    "                name = tokens[1] # random varible name\n",
    "                line_ = myfile.readline() # read next line\n",
    "                line_ = line_.strip()\n",
    "                tokens_ = line_.split()\n",
    "                for i in range(3,len(tokens_)-1):\n",
    "                    values.append(tokens_[i])\n",
    "                new_node = Graph_Node(name = name, n = len(values), vals = values)\n",
    "                Alarm.addNode(new_node)\n",
    "\n",
    "            \n",
    "            if first_word == \"probability\":\n",
    "                vals = []\n",
    "                temp = tokens[2]\n",
    "                node = Alarm.search_node(temp)\n",
    "                index = Alarm.get_index(temp)\n",
    "                i = 3\n",
    "                # setting parents\n",
    "                while True:\n",
    "                    if tokens[i]==\")\":\n",
    "                        break\n",
    "                    node_ = Alarm.search_node(tokens[i])\n",
    "                    node_.add_child(index)\n",
    "                    vals.append(tokens[i])\n",
    "                    i = i + 1\n",
    "\n",
    "                node.set_Parents(vals)\n",
    "\n",
    "                line_ = myfile.readline().replace(\",\",\" \")\n",
    "                #print(\"line_:\", line_)\n",
    "                tokens_ = line_.split()\n",
    "                curr_CPT = []\n",
    "                for i in range(1,len(tokens_)-1):\n",
    "                    curr_CPT.append(float(tokens_[i]))\n",
    "\n",
    "                node.set_CPT(curr_CPT)\n",
    "\n",
    "    myfile.close()\n",
    "\n",
    "    return Alarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2 3 4'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line = \"2,3,4\"\n",
    "line = line.replace(\",\",\" \")\n",
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "bPath = \"/media/aknirala/c6ed7430-6a77-48e0-920c-777be00c9dc21/PhD/Thesis/GraphMod/bayesian-network-learning/data/\"\n",
    "gold_alarm = bPath + \"gold_alarm.bif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = read_network(gold_alarm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node NOT found\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'add_child'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-ef88ad2d0462>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mearthquake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"earthquake.bif\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mearthquake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPres_Graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-0de20b2e988b>\u001b[0m in \u001b[0;36mread_network\u001b[0;34m(bif_filepath)\u001b[0m\n\u001b[1;32m     39\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                     \u001b[0mnode_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAlarm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                     \u001b[0mnode_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m                     \u001b[0mvals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'add_child'"
     ]
    }
   ],
   "source": [
    "earthquake = \"earthquake.bif\"\n",
    "G = read_network(earthquake)\n",
    "type(G), G.Pres_Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('\"Hypovolemia\"', <__main__.Graph_Node at 0x7fb5b65a4390>),\n",
       "             ('\"StrokeVolume\"', <__main__.Graph_Node at 0x7fb5b65a4c88>),\n",
       "             ('\"LVFailure\"', <__main__.Graph_Node at 0x7fb5b65a4400>),\n",
       "             ('\"LVEDVolume\"', <__main__.Graph_Node at 0x7fb5b65a45f8>),\n",
       "             ('\"PCWP\"', <__main__.Graph_Node at 0x7fb5b6586898>),\n",
       "             ('\"CVP\"', <__main__.Graph_Node at 0x7fb5b65a4e10>),\n",
       "             ('\"History\"', <__main__.Graph_Node at 0x7fb5b65a4dd8>),\n",
       "             ('\"MinVolSet\"', <__main__.Graph_Node at 0x7fb5b65a4160>),\n",
       "             ('\"VentMach\"', <__main__.Graph_Node at 0x7fb5b6586b70>),\n",
       "             ('\"Disconnect\"', <__main__.Graph_Node at 0x7fb5b65ed278>),\n",
       "             ('\"VentTube\"', <__main__.Graph_Node at 0x7fb5b65ed550>),\n",
       "             ('\"KinkedTube\"', <__main__.Graph_Node at 0x7fb5b65ed780>),\n",
       "             ('\"Press\"', <__main__.Graph_Node at 0x7fb5b65ed860>),\n",
       "             ('\"ErrLowOutput\"', <__main__.Graph_Node at 0x7fb5b65ed8d0>),\n",
       "             ('\"HRBP\"', <__main__.Graph_Node at 0x7fb5b65edd68>),\n",
       "             ('\"ErrCauter\"', <__main__.Graph_Node at 0x7fb5b65ed5c0>),\n",
       "             ('\"HREKG\"', <__main__.Graph_Node at 0x7fb5b65ed940>),\n",
       "             ('\"HRSat\"', <__main__.Graph_Node at 0x7fb5b65edf60>),\n",
       "             ('\"BP\"', <__main__.Graph_Node at 0x7fb5b658de10>),\n",
       "             ('\"CO\"', <__main__.Graph_Node at 0x7fb5b658dcf8>),\n",
       "             ('\"HR\"', <__main__.Graph_Node at 0x7fb5b657fe10>),\n",
       "             ('\"TPR\"', <__main__.Graph_Node at 0x7fb5b657fc18>),\n",
       "             ('\"Anaphylaxis\"', <__main__.Graph_Node at 0x7fb5b657f470>),\n",
       "             ('\"InsuffAnesth\"', <__main__.Graph_Node at 0x7fb5b6593278>),\n",
       "             ('\"PAP\"', <__main__.Graph_Node at 0x7fb5b65930b8>),\n",
       "             ('\"PulmEmbolus\"', <__main__.Graph_Node at 0x7fb5b65936d8>),\n",
       "             ('\"FiO2\"', <__main__.Graph_Node at 0x7fb5b6593550>),\n",
       "             ('\"Catechol\"', <__main__.Graph_Node at 0x7fb5b6593828>),\n",
       "             ('\"SaO2\"', <__main__.Graph_Node at 0x7fb5b6593588>),\n",
       "             ('\"Shunt\"', <__main__.Graph_Node at 0x7fb5b6593860>),\n",
       "             ('\"PVSat\"', <__main__.Graph_Node at 0x7fb5b657f780>),\n",
       "             ('\"MinVol\"', <__main__.Graph_Node at 0x7fb5b65a00f0>),\n",
       "             ('\"ExpCO2\"', <__main__.Graph_Node at 0x7fb5b65a0278>),\n",
       "             ('\"ArtCO2\"', <__main__.Graph_Node at 0x7fb5b65a0400>),\n",
       "             ('\"VentAlv\"', <__main__.Graph_Node at 0x7fb5b65a0588>),\n",
       "             ('\"VentLung\"', <__main__.Graph_Node at 0x7fb5b65a06d8>),\n",
       "             ('\"Intubation\"', <__main__.Graph_Node at 0x7fb5b65a0860>)])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.Pres_Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
